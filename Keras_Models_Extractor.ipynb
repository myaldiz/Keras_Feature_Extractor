{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Pretrained Models Feature Extractor\n",
    "\n",
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_model = keras.applications.ResNet50(weights='imagenet', include_top=True)\n",
    "feature_vector_last = resnet_model.layers[-1]\n",
    "feature_vector_fclast = resnet_model.layers[-2]\n",
    "feature_extractor_1 = keras.Model(inputs=resnet_model.input, outputs=feature_vector_last.output)\n",
    "feature_extractor_2 = keras.Model(inputs=resnet_model.input, outputs=feature_vector_fclast.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resnet_model = keras.applications.Xception()\n",
    "#feature_vector_last = resnet_model.layers[-1]\n",
    "#feature_vector_fclast = resnet_model.layers[-2]\n",
    "#feature_extractor_1 = keras.Model(inputs=resnet_model.input, outputs=feature_vector_last.output)\n",
    "#feature_extractor_2 = keras.Model(inputs=resnet_model.input, outputs=feature_vector_fclast.output)\n",
    "print(resnet_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This does not work, need changes\n",
    "resnet_model = keras.applications.InceptionResNetV2(weights='imagenet', include_top=True)\n",
    "feature_vector_last = resnet_model.layers[-1]\n",
    "feature_vector_fclast = resnet_model.layers[-3]\n",
    "feature_extractor_1 = keras.Model(inputs=resnet_model.input, outputs=feature_vector_last.output)\n",
    "feature_extractor_2 = keras.Model(inputs=resnet_model.input, outputs=feature_vector_fclast.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    try:\n",
    "        tmp_data = np.array(Image.open(path))\n",
    "    except:\n",
    "        print('Exception', sys.exc_info())\n",
    "        return np.array([])\n",
    "    \n",
    "    return tmp_data\n",
    "\n",
    "def print_predictions(preds, top_num=5):\n",
    "    print('Predicted top %d: ' % top_num)\n",
    "    pred_str = keras.applications.resnet50.decode_predictions(preds, top=top_num)[0]\n",
    "    for i in range(top_num):\n",
    "        print(pred_str[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = 'data/test.jpg'\n",
    "img = imread(img_path)\n",
    "img = np.array(cv2.resize(img, (224,224)))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = img.astype(np.float32)\n",
    "x = np.expand_dims(img, axis=0)\n",
    "#x = keras.applications.resnet50.preprocess_input(x)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "preds = resnet_model.predict(x)\n",
    "print_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(img_path, target_size=(224,224))\n",
    "x = keras.preprocessing.image.img_to_array(img)\n",
    "plt.imshow(x / 255.0)\n",
    "plt.show()\n",
    "x = np.expand_dims(x,axis=0)\n",
    "#x = keras.applications.resnet50.preprocess_input(x)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "preds = resnet_model.predict(x)\n",
    "print_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opencv uses probably interpolation rather than nearest neighbour, will be better choice for us.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train test csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_dir = '/home/myaldiz/Desktop/keras_transfer_learning/data/'\n",
    "\n",
    "def path_list(path):\n",
    "    relative_list = []\n",
    "    labels = []\n",
    "    class_index = 0\n",
    "    for i in os.listdir(path):\n",
    "        tmp_path = path + i + '/'\n",
    "        tmp_rel_path = i + '/'\n",
    "        for j in os.listdir(tmp_path):\n",
    "            relative_list.append(tmp_rel_path + j)\n",
    "            labels.append(class_index)\n",
    "        class_index = class_index + 1\n",
    "    return relative_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'Train/'\n",
    "dirs, labels = path_list(home_dir+dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_place = home_dir + dataset_dir[:-1]+'.csv'\n",
    "with open(file_place, 'w', newline='') as csvfile:\n",
    "    data_writer = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for file_loc, label in zip(dirs, labels):\n",
    "        data_writer.writerow([file_loc, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Features for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_features(dirs, model1, model2):\n",
    "    batch_size = 100 \n",
    "    batch_index = 1\n",
    "    images = []\n",
    "    features1 = []\n",
    "    features2 = []\n",
    "    for file_loc in dirs:\n",
    "        path = home_dir + dataset_dir + file_loc \n",
    "        img_temp = keras.preprocessing.image.load_img(path, target_size=(224,224))\n",
    "        img_temp = keras.preprocessing.image.img_to_array(img_temp)\n",
    "        #img_temp = imread(path)\n",
    "        #img_temp = np.array(cv2.resize(img_temp, (224,224))).astype(np.float32)\n",
    "        images.append(img_temp)\n",
    "        \n",
    "        if batch_index == batch_size:\n",
    "            image_batch = np.stack(images)\n",
    "            #image_batch = keras.applications.resnet50.preprocess_input(image_batch)\n",
    "            image_batch = keras.applications.vgg19.preprocess_input(image_batch)\n",
    "            batch_features = model1.predict(image_batch)\n",
    "            features1.append(batch_features)\n",
    "            batch_features = model2.predict(image_batch)\n",
    "            features2.append(batch_features)\n",
    "            images = []\n",
    "            batch_index = 0\n",
    "        \n",
    "        batch_index = batch_index + 1\n",
    "    \n",
    "    if batch_index != 1:\n",
    "        image_batch = np.stack(images)\n",
    "        batch_features = model1.predict(image_batch)\n",
    "        features1.append(batch_features)\n",
    "        batch_features = model2.predict(image_batch)\n",
    "        features2.append(batch_features)\n",
    "        \n",
    "    print('Features Calculated..')\n",
    "    return np.concatenate(features1), np.concatenate(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'Train/'\n",
    "dirs, labels = path_list(home_dir+dataset_dir)\n",
    "X_train1, X_train2 = calculate_features(dirs, feature_extractor_1, feature_extractor_2)\n",
    "y_train = np.array(labels)\n",
    "print(X_train1.shape, X_train2.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'Test1/'\n",
    "dirs, labels = path_list(home_dir+dataset_dir)\n",
    "X_test1_1, X_test1_2 = calculate_features(dirs, feature_extractor_1, feature_extractor_2)\n",
    "y_test1 = np.array(labels)\n",
    "print(X_test1_1.shape, X_test1_2.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'Test2/'\n",
    "dirs, labels = path_list(home_dir+dataset_dir)\n",
    "X_test2_1, X_test2_2 = calculate_features(dirs, feature_extractor_1, feature_extractor_2)\n",
    "y_test2 = np.array(labels)\n",
    "print(X_test2_1.shape, X_test2_2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'Test3/'\n",
    "dirs, labels = path_list(home_dir+dataset_dir)\n",
    "X_test3_1, X_test3_2 = calculate_features(dirs, feature_extractor_1, feature_extractor_2)\n",
    "y_test3 = np.array(labels)\n",
    "print(X_test3_1.shape, X_test3_2.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Linear Models from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier1 = svm.LinearSVC()\n",
    "classifier1.fit(X_train1, y_train)\n",
    "print('Test1 softmax: ', classifier1.score(X_test1_1, y_test1))\n",
    "print('Test2 softmax: ', classifier1.score(X_test2_1, y_test2))\n",
    "print('Test3 softmax: ', classifier1.score(X_test3_1, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier2 = svm.LinearSVC()\n",
    "classifier2.fit(X_train2, y_train)\n",
    "print('Test1 fc_last: ', classifier2.score(X_test1_2, y_test1))\n",
    "print('Test2 fc_last: ', classifier2.score(X_test2_2, y_test2))\n",
    "print('Test3 fc_last: ', classifier2.score(X_test3_2, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "print('Train:')\n",
    "y_predict = classifier2.predict(X_train2)\n",
    "print(classification_report(y_predict, y_train, target_names=target_names))\n",
    "\n",
    "print('Test1:')\n",
    "y_predict = classifier2.predict(X_test1_2)\n",
    "print(classification_report(y_predict, y_test1, target_names=target_names))\n",
    "\n",
    "print('Test2:')\n",
    "y_predict = classifier2.predict(X_test2_2)\n",
    "print(classification_report(y_predict, y_test2, target_names=target_names))\n",
    "\n",
    "print('Test3:')\n",
    "y_predict = classifier2.predict(X_test3_2)\n",
    "print(classification_report(y_predict, y_test3, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
